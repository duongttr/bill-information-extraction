{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation_models "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGdN7FgkW0EY",
        "outputId": "200c7eea-2f3f-4b16-e808-6b9cd66490aa"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: segmentation_models in /usr/local/lib/python3.8/dist-packages (1.0.1)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.8/dist-packages (from segmentation_models) (1.0.8)\n",
            "Requirement already satisfied: efficientnet==1.0.0 in /usr/local/lib/python3.8/dist-packages (from segmentation_models) (1.0.0)\n",
            "Requirement already satisfied: image-classifiers==1.0.0 in /usr/local/lib/python3.8/dist-packages (from segmentation_models) (1.0.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (from efficientnet==1.0.0->segmentation_models) (0.19.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.8/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (23.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.4.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (8.4.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.9.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.10.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2023.2.27)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsCqUCaTWDcT",
        "outputId": "64dd2d17-e2bd-4488-df89-e12ca4496a10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: SM_FRAMEWORK=tf.keras\n"
          ]
        }
      ],
      "source": [
        "%env SM_FRAMEWORK=tf.keras\n",
        "import segmentation_models as sm\n",
        "import keras \n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.layers import Input, Conv2D\n",
        "from keras.models import Model\n",
        "from google.colab import drive\n",
        "from PIL import Image, ImageOps\n",
        "from tensorflow.keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lspPmYSmBDm",
        "outputId": "3b337c56-c6a3-471f-9637-76b64527bede"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.set_image_data_format('channels_last')"
      ],
      "metadata": {
        "id": "8ph_Y335WklS"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data prepairation"
      ],
      "metadata": {
        "id": "pZljkMcBafzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_size(path, size, padding):\n",
        "  image = Image.open(path)\n",
        "  image = ImageOps.grayscale(image)\n",
        "  size = size - padding\n",
        "  s = image.size\n",
        "  if s[0] <= s[1]:\n",
        "    image = image.resize((int(s[0]*(size/s[1])), size))\n",
        "  else:\n",
        "    image = image.resize((size, int(s[1]*(size/s[0]))))\n",
        "\n",
        "  new_size = image.size\n",
        "  delta_w = size - new_size[0] + padding\n",
        "  delta_h = size - new_size[1] + padding\n",
        "  padding = (delta_w//2, delta_h//2, delta_w-(delta_w//2), delta_h-(delta_h//2))\n",
        "  new_img = np.array(ImageOps.expand(image, padding)).astype('float32')\n",
        "\n",
        "  if len(new_img.shape) == 2:\n",
        "    return new_img.reshape(256, 256, 1) / 255\n",
        "\n",
        "  else:\n",
        "     return new_img / 255\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "EwMkcjWqptph"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable setting\n",
        "image = []\n",
        "mask = []\n",
        "ratio = 0.7\n",
        "resize = 256\n",
        "padding = 10"
      ],
      "metadata": {
        "id": "IuAxQUgDzzJ0"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_root = '/content/drive/MyDrive/Dataset/1 - Raw/self_collected/'\n",
        "mask_root = '/content/drive/MyDrive/Masked_image/Mask/'\n",
        "\n",
        "print(\"Image:\", len(os.listdir(image_root)))\n",
        "print(\"Mask:\", len(os.listdir(mask_root)))"
      ],
      "metadata": {
        "id": "CNxW0m5MafcM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61e671d8-3bfd-4f9f-e0a0-cd7821421d98"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 401\n",
            "Mask: 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for path in os.listdir(mask_root):\n",
        "  image.append(reduce_size(image_root + path, resize, padding))\n",
        "  mask.append(reduce_size(mask_root + path, resize, padding))"
      ],
      "metadata": {
        "id": "BnQjZXrezs7G"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_root = '/content/drive/MyDrive/Dataset/1 - Raw/mc_ocr/'\n",
        "mask_root = '/content/drive/MyDrive/Masked_image/Mask1/'\n",
        "\n",
        "print(\"Image:\", len(os.listdir(image_root)))\n",
        "print(\"Mask:\", len(os.listdir(mask_root)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkTJjuTZ1NW8",
        "outputId": "5704f9de-7777-41c6-cc4d-fa4bfcd0603b"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: 1155\n",
            "Mask: 1155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for path in os.listdir(mask_root):\n",
        "  image.append(reduce_size(image_root + path, resize, padding))\n",
        "  mask.append(reduce_size(mask_root + path, resize, padding))"
      ],
      "metadata": {
        "id": "51e0rn_2AcQU"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids = np.arange(len(image))\n",
        "np.random.shuffle(ids)\n",
        "image = np.array(image)[ids]\n",
        "mask = np.array(mask)[ids]"
      ],
      "metadata": {
        "id": "Tlt8sHcrSfPo"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = []\n",
        "train_y = []\n",
        "val_x = []\n",
        "val_y = []\n",
        "\n",
        "length = len(image)\n",
        "\n",
        "train_x = image[:int(length*ratio)]\n",
        "train_y = mask[:int(length*ratio)]\n",
        "\n",
        "val_x = image[int(length*ratio):]\n",
        "val_y = mask[int(length*ratio):]"
      ],
      "metadata": {
        "id": "xnKEWx4WYIAI"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = []\n",
        "mask = []"
      ],
      "metadata": {
        "id": "1zwDJQTETOrA"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model "
      ],
      "metadata": {
        "id": "NTkMfxrytmVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BACKBONE = 'resnet34'\n",
        "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
        "\n",
        "# preprocess input\n",
        "train_x = np.stack(preprocess_input(train_x))\n",
        "val_x = np.stack(preprocess_input(val_x))\n",
        "\n",
        "# define model\n",
        "N = train_x.shape[-1]\n",
        "model = sm.Unet(BACKBONE, encoder_weights=None, input_shape=(None, None, N))\n",
        "\n",
        "\"\"\"inp = Input(shape=(None, None, N))\n",
        "l1 = Conv2D(3, (1, 1))(inp) # map N channels data to 3 channels\n",
        "out = model(l1)\n",
        "\n",
        "model = Model(inp, out, name=model.name)\"\"\"\n",
        "\n",
        "model.compile(\n",
        "    'Adam',\n",
        "    loss=sm.losses.bce_jaccard_loss,\n",
        "    metrics=[sm.metrics.iou_score],\n",
        ")"
      ],
      "metadata": {
        "id": "dBQL058ShLs5"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit model\n",
        "# if you use data generator use model.fit_generator(...) instead of model.fit(...)\n",
        "# more about `fit_generator` here: https://keras.io/models/sequential/#fit_generator\n",
        "model.fit(\n",
        "   x=train_x,\n",
        "   y=train_y,\n",
        "   batch_size=16,\n",
        "   epochs=7,\n",
        "   shuffle=True,\n",
        "   validation_data=(val_x, val_y)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "QHLA9BgM8qbM",
        "outputId": "b8a9b873-ac0d-43fa-a84f-bebbeb3d8ccb"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "68/68 [==============================] - 1200s 18s/step - loss: 0.0983 - iou_score: 0.9484 - val_loss: 0.1538 - val_iou_score: 0.9342\n",
            "Epoch 2/7\n",
            "68/68 [==============================] - 1195s 18s/step - loss: 0.0979 - iou_score: 0.9489 - val_loss: 0.5433 - val_iou_score: 0.8327\n",
            "Epoch 3/7\n",
            "68/68 [==============================] - 1204s 18s/step - loss: 0.1000 - iou_score: 0.9478 - val_loss: 0.1523 - val_iou_score: 0.9385\n",
            "Epoch 4/7\n",
            "68/68 [==============================] - 1200s 18s/step - loss: 0.0718 - iou_score: 0.9627 - val_loss: 0.2416 - val_iou_score: 0.9020\n",
            "Epoch 5/7\n",
            "32/68 [=============>................] - ETA: 9:21 - loss: 0.0848 - iou_score: 0.9574"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-0192ba585aba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# if you use data generator use model.fit_generator(...) instead of model.fit(...)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# more about `fit_generator` here: https://keras.io/models/sequential/#fit_generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      5\u001b[0m    \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m    \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save model"
      ],
      "metadata": {
        "id": "AjQ9CoAva_J9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/Model/Invoice_Segmentation_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UrGPnSZD2Fo",
        "outputId": "cb6a8987-e1b2-4027-976d-35daed8a6aa2"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 49). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load model"
      ],
      "metadata": {
        "id": "A62ZN9lqbUaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = keras.models.load_model(\"/content/Model/Invoice_Segmentation_model.h5\", compile=False)"
      ],
      "metadata": {
        "id": "SXvI3hEgbVwN"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = loaded_model.predict(val_x[1].reshape((1, 256, 256, 1))).reshape((256, 256, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31uE9EP-biSf",
        "outputId": "9fa880ab-2272-4cfc-922b-224638169cf3"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(121)\n",
        "plt.imshow(test)\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.imshow(val_y[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "dRxviTLxk7Oe",
        "outputId": "19ffb1af-a8a0-4648-cb77-6d232ff3d5b9"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f40b7a05d90>"
            ]
          },
          "metadata": {},
          "execution_count": 117
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}